{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   x         20000 non-null  float64\n",
      " 1   y         20000 non-null  float64\n",
      " 2   pitch     20000 non-null  float64\n",
      " 3   shoulder  20000 non-null  float64\n",
      " 4   elbow     20000 non-null  float64\n",
      " 5   wrist     20000 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "# path = '../datasets/position_data.csv'\n",
    "# path = '../datasets/virtual_data_example_pkg.csv'\n",
    "# path = '../datasets/virtual_data_1.csv'\n",
    "path = './data.csv'\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data['x'], data['y'], marker='x', color='blue', markersize=1)\n",
    "\n",
    "plt.title('x and y positions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data[['x','y','pitch']].to_numpy()\n",
    "y = data[['shoulder','elbow','wrist']].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and Training a Model with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(3, 100, bias=1)\n",
    "        self.output_layer = nn.Linear(100, 3)\n",
    "        self.activation_function = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation_function(self.hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_one_epoch(dataloader, model, optimizer, mse):\n",
    "    # the running loss is the mean of the losses accumulated\n",
    "    # from a batch\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        # zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # computes the loss and its gradients\n",
    "        loss = mse(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        # adjust weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # every 1000 batches, compute the mean of the loss\n",
    "        if batch_idx % 1000 == 999:\n",
    "            # compute the mean of the running_loss\n",
    "            last_loss = running_loss / 1000\n",
    "            print(f'  batch {batch_idx} loss: {last_loss}')\n",
    "            running_loss = 0.\n",
    "    \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "  batch 999 loss: 1.0169130875915289\n",
      "  batch 1999 loss: 0.9181321322321891\n",
      "  batch 2999 loss: 0.8802516161575913\n",
      "  batch 3999 loss: 0.8665538013279438\n",
      "LOSS train 0.8665538013279438 valid 0.8759682774543762\n",
      "Epoch [1/100], Loss: 0.8760\n",
      "Epoch: 2\n",
      "  batch 999 loss: 0.8831738030016423\n",
      "  batch 1999 loss: 0.8798160646110773\n",
      "  batch 2999 loss: 0.8605269351452589\n",
      "  batch 3999 loss: 0.8525394633710385\n",
      "LOSS train 0.8525394633710385 valid 0.862469494342804\n",
      "Epoch [2/100], Loss: 0.8625\n",
      "Epoch: 3\n",
      "  batch 999 loss: 0.8690819364190102\n",
      "  batch 1999 loss: 0.8642707022503019\n",
      "  batch 2999 loss: 0.8428107844814658\n",
      "  batch 3999 loss: 0.8330897718071938\n",
      "LOSS train 0.8330897718071938 valid 0.8405073881149292\n",
      "Epoch [3/100], Loss: 0.8405\n",
      "Epoch: 4\n",
      "  batch 999 loss: 0.8472444207370281\n",
      "  batch 1999 loss: 0.8388930339738727\n",
      "  batch 2999 loss: 0.815900785908103\n",
      "  batch 3999 loss: 0.8054876173734665\n",
      "LOSS train 0.8054876173734665 valid 0.811892569065094\n",
      "Epoch [4/100], Loss: 0.8119\n",
      "Epoch: 5\n",
      "  batch 999 loss: 0.8190449255853891\n",
      "  batch 1999 loss: 0.8099614052698016\n",
      "  batch 2999 loss: 0.7897561413645744\n",
      "  batch 3999 loss: 0.7811252185851335\n",
      "LOSS train 0.7811252185851335 valid 0.789702832698822\n",
      "Epoch [5/100], Loss: 0.7897\n",
      "Epoch: 6\n",
      "  batch 999 loss: 0.7965341363102197\n",
      "  batch 1999 loss: 0.7891148811802268\n",
      "  batch 2999 loss: 0.7723542429357767\n",
      "  batch 3999 loss: 0.7643919166624547\n",
      "LOSS train 0.7643919166624547 valid 0.7750753164291382\n",
      "Epoch [6/100], Loss: 0.7751\n",
      "Epoch: 7\n",
      "  batch 999 loss: 0.7804898854643106\n",
      "  batch 1999 loss: 0.7734023521617055\n",
      "  batch 2999 loss: 0.7570590175017714\n",
      "  batch 3999 loss: 0.7475642871111632\n",
      "LOSS train 0.7475642871111632 valid 0.7584385275840759\n",
      "Epoch [7/100], Loss: 0.7584\n",
      "Epoch: 8\n",
      "  batch 999 loss: 0.7618882813304663\n",
      "  batch 1999 loss: 0.7520980969592929\n",
      "  batch 2999 loss: 0.7317730357460678\n",
      "  batch 3999 loss: 0.7176643740683794\n",
      "LOSS train 0.7176643740683794 valid 0.7259605526924133\n",
      "Epoch [8/100], Loss: 0.7260\n",
      "Epoch: 9\n",
      "  batch 999 loss: 0.7259557408243418\n",
      "  batch 1999 loss: 0.7087948811277747\n",
      "  batch 2999 loss: 0.6817547228224575\n",
      "  batch 3999 loss: 0.6623006576299667\n",
      "LOSS train 0.6623006576299667 valid 0.6683403849601746\n",
      "Epoch [9/100], Loss: 0.6683\n",
      "Epoch: 10\n",
      "  batch 999 loss: 0.6656565339192748\n",
      "  batch 1999 loss: 0.6427545328252018\n",
      "  batch 2999 loss: 0.6187481213659048\n",
      "  batch 3999 loss: 0.6037380366623402\n",
      "LOSS train 0.6037380366623402 valid 0.6129599809646606\n",
      "Epoch [10/100], Loss: 0.6130\n",
      "Epoch: 11\n",
      "  batch 999 loss: 0.6121596091836691\n",
      "  batch 1999 loss: 0.5927690695859492\n",
      "  batch 2999 loss: 0.5803090536110103\n",
      "  batch 3999 loss: 0.5736616300679743\n",
      "LOSS train 0.5736616300679743 valid 0.5860549807548523\n",
      "Epoch [11/100], Loss: 0.5861\n",
      "Epoch: 12\n",
      "  batch 999 loss: 0.5868354337438941\n",
      "  batch 1999 loss: 0.5707607875019312\n",
      "  batch 2999 loss: 0.5641577883847058\n",
      "  batch 3999 loss: 0.5610158884450793\n",
      "LOSS train 0.5610158884450793 valid 0.5738123655319214\n",
      "Epoch [12/100], Loss: 0.5738\n",
      "Epoch: 13\n",
      "  batch 999 loss: 0.5749185934215784\n",
      "  batch 1999 loss: 0.5599641976468265\n",
      "  batch 2999 loss: 0.5547269727662205\n",
      "  batch 3999 loss: 0.5527696757689118\n",
      "LOSS train 0.5527696757689118 valid 0.5653015971183777\n",
      "Epoch [13/100], Loss: 0.5653\n",
      "Epoch: 14\n",
      "  batch 999 loss: 0.5665076728612185\n",
      "  batch 1999 loss: 0.5521511048376561\n",
      "  batch 2999 loss: 0.5469255751296878\n",
      "  batch 3999 loss: 0.545522797614336\n",
      "LOSS train 0.545522797614336 valid 0.5577654838562012\n",
      "Epoch [14/100], Loss: 0.5578\n",
      "Epoch: 15\n",
      "  batch 999 loss: 0.559104196369648\n",
      "  batch 1999 loss: 0.5452310392968357\n",
      "  batch 2999 loss: 0.539640206374228\n",
      "  batch 3999 loss: 0.5385309882983565\n",
      "LOSS train 0.5385309882983565 valid 0.5504496097564697\n",
      "Epoch [15/100], Loss: 0.5504\n",
      "Epoch: 16\n",
      "  batch 999 loss: 0.5520346682816744\n",
      "  batch 1999 loss: 0.5385678493753076\n",
      "  batch 2999 loss: 0.5324518949389457\n",
      "  batch 3999 loss: 0.5314598797000945\n",
      "LOSS train 0.5314598797000945 valid 0.5430065393447876\n",
      "Epoch [16/100], Loss: 0.5430\n",
      "Epoch: 17\n",
      "  batch 999 loss: 0.5449604066610336\n",
      "  batch 1999 loss: 0.5318167973384261\n",
      "  batch 2999 loss: 0.5250523304268718\n",
      "  batch 3999 loss: 0.524023067843169\n",
      "LOSS train 0.524023067843169 valid 0.5351877808570862\n",
      "Epoch [17/100], Loss: 0.5352\n",
      "Epoch: 18\n",
      "  batch 999 loss: 0.5375959597080946\n",
      "  batch 1999 loss: 0.5246883908770978\n",
      "  batch 2999 loss: 0.5171497560068965\n",
      "  batch 3999 loss: 0.5159395274296403\n",
      "LOSS train 0.5159395274296403 valid 0.5268073081970215\n",
      "Epoch [18/100], Loss: 0.5268\n",
      "Epoch: 19\n",
      "  batch 999 loss: 0.5296703674197197\n",
      "  batch 1999 loss: 0.516918834336102\n",
      "  batch 2999 loss: 0.5084845107793808\n",
      "  batch 3999 loss: 0.5069673590734601\n",
      "LOSS train 0.5069673590734601 valid 0.5177639722824097\n",
      "Epoch [19/100], Loss: 0.5178\n",
      "Epoch: 20\n",
      "  batch 999 loss: 0.5209524352625012\n",
      "  batch 1999 loss: 0.5083023643791675\n",
      "  batch 2999 loss: 0.4988718362599611\n",
      "  batch 3999 loss: 0.4969411499463022\n",
      "LOSS train 0.4969411499463022 valid 0.5080416798591614\n",
      "Epoch [20/100], Loss: 0.5080\n",
      "Epoch: 21\n",
      "  batch 999 loss: 0.511272080026567\n",
      "  batch 1999 loss: 0.4987003310956061\n",
      "  batch 2999 loss: 0.4881918997168541\n",
      "  batch 3999 loss: 0.48574429702013733\n",
      "LOSS train 0.48574429702013733 valid 0.4976270794868469\n",
      "Epoch [21/100], Loss: 0.4976\n",
      "Epoch: 22\n",
      "  batch 999 loss: 0.5005096328705549\n",
      "  batch 1999 loss: 0.48800717237964275\n",
      "  batch 2999 loss: 0.4763857930600643\n",
      "  batch 3999 loss: 0.47333182256296275\n",
      "LOSS train 0.47333182256296275 valid 0.4864885210990906\n",
      "Epoch [22/100], Loss: 0.4865\n",
      "Epoch: 23\n",
      "  batch 999 loss: 0.48866257232427596\n",
      "  batch 1999 loss: 0.4762562299817801\n",
      "  batch 2999 loss: 0.46363363548368214\n",
      "  batch 3999 loss: 0.45992983801662923\n",
      "LOSS train 0.45992983801662923 valid 0.47476813197135925\n",
      "Epoch [23/100], Loss: 0.4748\n",
      "Epoch: 24\n",
      "  batch 999 loss: 0.47603399116545914\n",
      "  batch 1999 loss: 0.46381780460849403\n",
      "  batch 2999 loss: 0.45050345991924406\n",
      "  batch 3999 loss: 0.4461865901835263\n",
      "LOSS train 0.4461865901835263 valid 0.46301791071891785\n",
      "Epoch [24/100], Loss: 0.4630\n",
      "Epoch: 25\n",
      "  batch 999 loss: 0.463407573916018\n",
      "  batch 1999 loss: 0.4514986983537674\n",
      "  batch 2999 loss: 0.4379747851155698\n",
      "  batch 3999 loss: 0.43319792713969946\n",
      "LOSS train 0.43319792713969946 valid 0.4521807134151459\n",
      "Epoch [25/100], Loss: 0.4522\n",
      "Epoch: 26\n",
      "  batch 999 loss: 0.45190586731955407\n",
      "  batch 1999 loss: 0.4403910924121737\n",
      "  batch 2999 loss: 0.4271276140920818\n",
      "  batch 3999 loss: 0.42209600725024937\n",
      "LOSS train 0.42209600725024937 valid 0.44304031133651733\n",
      "Epoch [26/100], Loss: 0.4430\n",
      "Epoch: 27\n",
      "  batch 999 loss: 0.4423822982013226\n",
      "  batch 1999 loss: 0.43127061806619166\n",
      "  batch 2999 loss: 0.4184670149572194\n",
      "  batch 3999 loss: 0.41335623639449476\n",
      "LOSS train 0.41335623639449476 valid 0.43562838435173035\n",
      "Epoch [27/100], Loss: 0.4356\n",
      "Epoch: 28\n",
      "  batch 999 loss: 0.434872557669878\n",
      "  batch 1999 loss: 0.4241001995913684\n",
      "  batch 2999 loss: 0.4116329989396036\n",
      "  batch 3999 loss: 0.4065912058018148\n",
      "LOSS train 0.4065912058018148 valid 0.42929038405418396\n",
      "Epoch [28/100], Loss: 0.4293\n",
      "Epoch: 29\n",
      "  batch 999 loss: 0.4287549125961959\n",
      "  batch 1999 loss: 0.4182632340788841\n",
      "  batch 2999 loss: 0.40591008304804566\n",
      "  batch 3999 loss: 0.40105444892123343\n",
      "LOSS train 0.40105444892123343 valid 0.4234302341938019\n",
      "Epoch [29/100], Loss: 0.4234\n",
      "Epoch: 30\n",
      "  batch 999 loss: 0.4234627186357975\n",
      "  batch 1999 loss: 0.41320438689738515\n",
      "  batch 2999 loss: 0.40089055894315245\n",
      "  batch 3999 loss: 0.3962380929104984\n",
      "LOSS train 0.3962380929104984 valid 0.4179861843585968\n",
      "Epoch [30/100], Loss: 0.4180\n",
      "Epoch: 31\n",
      "  batch 999 loss: 0.41883419413119555\n",
      "  batch 1999 loss: 0.40871245695278047\n",
      "  batch 2999 loss: 0.39650477638468146\n",
      "  batch 3999 loss: 0.39197838999331\n",
      "LOSS train 0.39197838999331 valid 0.41310250759124756\n",
      "Epoch [31/100], Loss: 0.4131\n",
      "Epoch: 32\n",
      "  batch 999 loss: 0.41485368785634635\n",
      "  batch 1999 loss: 0.40475575454160573\n",
      "  batch 2999 loss: 0.3927351367473602\n",
      "  batch 3999 loss: 0.38823628820478917\n",
      "LOSS train 0.38823628820478917 valid 0.4088226854801178\n",
      "Epoch [32/100], Loss: 0.4088\n",
      "Epoch: 33\n",
      "  batch 999 loss: 0.41145656537637115\n",
      "  batch 1999 loss: 0.4013026348426938\n",
      "  batch 2999 loss: 0.3895120915919542\n",
      "  batch 3999 loss: 0.38495498728007077\n",
      "LOSS train 0.38495498728007077 valid 0.40508943796157837\n",
      "Epoch [33/100], Loss: 0.4051\n",
      "Epoch: 34\n",
      "  batch 999 loss: 0.40852930400520565\n",
      "  batch 1999 loss: 0.3982739666253328\n",
      "  batch 2999 loss: 0.3867252150736749\n",
      "  batch 3999 loss: 0.38204066203162074\n",
      "LOSS train 0.38204066203162074 valid 0.40179893374443054\n",
      "Epoch [34/100], Loss: 0.4018\n",
      "Epoch: 35\n",
      "  batch 999 loss: 0.4059396788161248\n",
      "  batch 1999 loss: 0.395558620005846\n",
      "  batch 2999 loss: 0.3842492443881929\n",
      "  batch 3999 loss: 0.37938158237189057\n",
      "LOSS train 0.37938158237189057 valid 0.3988296687602997\n",
      "Epoch [35/100], Loss: 0.3988\n",
      "Epoch: 36\n",
      "  batch 999 loss: 0.4035593210123479\n",
      "  batch 1999 loss: 0.3930382348001003\n",
      "  batch 2999 loss: 0.3819639218859375\n",
      "  batch 3999 loss: 0.37686772898212073\n",
      "LOSS train 0.37686772898212073 valid 0.3960677981376648\n",
      "Epoch [36/100], Loss: 0.3961\n",
      "Epoch: 37\n",
      "  batch 999 loss: 0.4012759252730757\n",
      "  batch 1999 loss: 0.390604776725173\n",
      "  batch 2999 loss: 0.3797653893455863\n",
      "  batch 3999 loss: 0.37440235578641295\n",
      "LOSS train 0.37440235578641295 valid 0.39340776205062866\n",
      "Epoch [37/100], Loss: 0.3934\n",
      "Epoch: 38\n",
      "  batch 999 loss: 0.398998351668939\n",
      "  batch 1999 loss: 0.38816803401708605\n",
      "  batch 2999 loss: 0.37756943644583224\n",
      "  batch 3999 loss: 0.37190662923082707\n",
      "LOSS train 0.37190662923082707 valid 0.3907681107521057\n",
      "Epoch [38/100], Loss: 0.3908\n",
      "Epoch: 39\n",
      "  batch 999 loss: 0.396655265500769\n",
      "  batch 1999 loss: 0.38565672894194725\n",
      "  batch 2999 loss: 0.37531084662675857\n",
      "  batch 3999 loss: 0.3693194919973612\n",
      "LOSS train 0.3693194919973612 valid 0.3880848288536072\n",
      "Epoch [39/100], Loss: 0.3881\n",
      "Epoch: 40\n",
      "  batch 999 loss: 0.3941921576354653\n",
      "  batch 1999 loss: 0.38301709646359083\n",
      "  batch 2999 loss: 0.3729409364685416\n",
      "  batch 3999 loss: 0.36659666687622666\n",
      "LOSS train 0.36659666687622666 valid 0.3853093981742859\n",
      "Epoch [40/100], Loss: 0.3853\n",
      "Epoch: 41\n",
      "  batch 999 loss: 0.39156965842656793\n",
      "  batch 1999 loss: 0.3802119082398713\n",
      "  batch 2999 loss: 0.3704268107414246\n",
      "  batch 3999 loss: 0.3637107920758426\n",
      "LOSS train 0.3637107920758426 valid 0.3824097514152527\n",
      "Epoch [41/100], Loss: 0.3824\n",
      "Epoch: 42\n",
      "  batch 999 loss: 0.38876381977833807\n",
      "  batch 1999 loss: 0.3772214625142515\n",
      "  batch 2999 loss: 0.36775198522955177\n",
      "  batch 3999 loss: 0.3606529234573245\n",
      "LOSS train 0.3606529234573245 valid 0.3793751001358032\n",
      "Epoch [42/100], Loss: 0.3794\n",
      "Epoch: 43\n",
      "  batch 999 loss: 0.38576885611377654\n",
      "  batch 1999 loss: 0.374046631526202\n",
      "  batch 2999 loss: 0.36491813383623956\n",
      "  batch 3999 loss: 0.3574343228787184\n",
      "LOSS train 0.3574343228787184 valid 0.37621167302131653\n",
      "Epoch [43/100], Loss: 0.3762\n",
      "Epoch: 44\n",
      "  batch 999 loss: 0.382600773897022\n",
      "  batch 1999 loss: 0.37071035876125097\n",
      "  batch 2999 loss: 0.3619463756456971\n",
      "  batch 3999 loss: 0.35408684353530406\n",
      "LOSS train 0.35408684353530406 valid 0.37294647097587585\n",
      "Epoch [44/100], Loss: 0.3729\n",
      "Epoch: 45\n",
      "  batch 999 loss: 0.3792984365560114\n",
      "  batch 1999 loss: 0.3672563239708543\n",
      "  batch 2999 loss: 0.35887407752871514\n",
      "  batch 3999 loss: 0.35065808112546804\n",
      "LOSS train 0.35065808112546804 valid 0.3696243464946747\n",
      "Epoch [45/100], Loss: 0.3696\n",
      "Epoch: 46\n",
      "  batch 999 loss: 0.3759173462167382\n",
      "  batch 1999 loss: 0.36374075131490824\n",
      "  batch 2999 loss: 0.3557483420446515\n",
      "  batch 3999 loss: 0.347203499302268\n",
      "LOSS train 0.347203499302268 valid 0.3662976622581482\n",
      "Epoch [46/100], Loss: 0.3663\n",
      "Epoch: 47\n",
      "  batch 999 loss: 0.3725185888148844\n",
      "  batch 1999 loss: 0.3602222655825317\n",
      "  batch 2999 loss: 0.3526176351867616\n",
      "  batch 3999 loss: 0.3437771642617881\n",
      "LOSS train 0.3437771642617881 valid 0.3630193769931793\n",
      "Epoch [47/100], Loss: 0.3630\n",
      "Epoch: 48\n",
      "  batch 999 loss: 0.36915774001181123\n",
      "  batch 1999 loss: 0.35675270254164937\n",
      "  batch 2999 loss: 0.34952508498355744\n",
      "  batch 3999 loss: 0.3404252744037658\n",
      "LOSS train 0.3404252744037658 valid 0.3598316013813019\n",
      "Epoch [48/100], Loss: 0.3598\n",
      "Epoch: 49\n",
      "  batch 999 loss: 0.3658780743815005\n",
      "  batch 1999 loss: 0.35337204653024673\n",
      "  batch 2999 loss: 0.34650464475527404\n",
      "  batch 3999 loss: 0.33718249887041746\n",
      "LOSS train 0.33718249887041746 valid 0.35676494240760803\n",
      "Epoch [49/100], Loss: 0.3568\n",
      "Epoch: 50\n",
      "  batch 999 loss: 0.3627094531059265\n",
      "  batch 1999 loss: 0.35010778819024563\n",
      "  batch 2999 loss: 0.3435806489363313\n",
      "  batch 3999 loss: 0.3340721308160573\n",
      "LOSS train 0.3340721308160573 valid 0.3538323938846588\n",
      "Epoch [50/100], Loss: 0.3538\n",
      "Epoch: 51\n",
      "  batch 999 loss: 0.3596700645722449\n",
      "  batch 1999 loss: 0.34697575352713467\n",
      "  batch 2999 loss: 0.3407682648524642\n",
      "  batch 3999 loss: 0.33110722819529476\n",
      "LOSS train 0.33110722819529476 valid 0.3510372042655945\n",
      "Epoch [51/100], Loss: 0.3510\n",
      "Epoch: 52\n",
      "  batch 999 loss: 0.3567687441147864\n",
      "  batch 1999 loss: 0.34398235474154354\n",
      "  batch 2999 loss: 0.33807549862563613\n",
      "  batch 3999 loss: 0.32829346402361986\n",
      "LOSS train 0.32829346402361986 valid 0.34837237000465393\n",
      "Epoch [52/100], Loss: 0.3484\n",
      "Epoch: 53\n",
      "  batch 999 loss: 0.35400839167833326\n",
      "  batch 1999 loss: 0.3411280527152121\n",
      "  batch 2999 loss: 0.3355053712762892\n",
      "  batch 3999 loss: 0.3256312249097973\n",
      "LOSS train 0.3256312249097973 valid 0.3458274304866791\n",
      "Epoch [53/100], Loss: 0.3458\n",
      "Epoch: 54\n",
      "  batch 999 loss: 0.35138766999915244\n",
      "  batch 1999 loss: 0.3384095423184335\n",
      "  batch 2999 loss: 0.33305740347132085\n",
      "  batch 3999 loss: 0.3231178057361394\n",
      "LOSS train 0.3231178057361394 valid 0.34339258074760437\n",
      "Epoch [54/100], Loss: 0.3434\n",
      "Epoch: 55\n",
      "  batch 999 loss: 0.3489032235294581\n",
      "  batch 1999 loss: 0.33582223451137544\n",
      "  batch 2999 loss: 0.3307288300991058\n",
      "  batch 3999 loss: 0.3207482192944735\n",
      "LOSS train 0.3207482192944735 valid 0.3410572409629822\n",
      "Epoch [55/100], Loss: 0.3411\n",
      "Epoch: 56\n",
      "  batch 999 loss: 0.34654965580254793\n",
      "  batch 1999 loss: 0.3333601316101849\n",
      "  batch 2999 loss: 0.32851486452668904\n",
      "  batch 3999 loss: 0.3185156378336251\n",
      "LOSS train 0.3185156378336251 valid 0.3388131856918335\n",
      "Epoch [56/100], Loss: 0.3388\n",
      "Epoch: 57\n",
      "  batch 999 loss: 0.3443206362053752\n",
      "  batch 1999 loss: 0.33101687255874274\n",
      "  batch 2999 loss: 0.3264095999598503\n",
      "  batch 3999 loss: 0.3164120227359235\n",
      "LOSS train 0.3164120227359235 valid 0.3366510570049286\n",
      "Epoch [57/100], Loss: 0.3367\n",
      "Epoch: 58\n",
      "  batch 999 loss: 0.34220868394523857\n",
      "  batch 1999 loss: 0.3287854728549719\n",
      "  batch 2999 loss: 0.32440602469816804\n",
      "  batch 3999 loss: 0.31442777744866907\n",
      "LOSS train 0.31442777744866907 valid 0.33456602692604065\n",
      "Epoch [58/100], Loss: 0.3346\n",
      "Epoch: 59\n",
      "  batch 999 loss: 0.34020584577694535\n",
      "  batch 1999 loss: 0.3266583319194615\n",
      "  batch 2999 loss: 0.322496601652354\n",
      "  batch 3999 loss: 0.31255286547169087\n",
      "LOSS train 0.31255286547169087 valid 0.3325515687465668\n",
      "Epoch [59/100], Loss: 0.3326\n",
      "Epoch: 60\n",
      "  batch 999 loss: 0.3383040639087558\n",
      "  batch 1999 loss: 0.324627789856866\n",
      "  batch 2999 loss: 0.32067402927950023\n",
      "  batch 3999 loss: 0.31077697084657846\n",
      "LOSS train 0.31077697084657846 valid 0.3306049704551697\n",
      "Epoch [60/100], Loss: 0.3306\n",
      "Epoch: 61\n",
      "  batch 999 loss: 0.3364953064955771\n",
      "  batch 1999 loss: 0.3226863717418164\n",
      "  batch 2999 loss: 0.31893094911798836\n",
      "  batch 3999 loss: 0.3090900694988668\n",
      "LOSS train 0.3090900694988668 valid 0.32872164249420166\n",
      "Epoch [61/100], Loss: 0.3287\n",
      "Epoch: 62\n",
      "  batch 999 loss: 0.33477215707302094\n",
      "  batch 1999 loss: 0.32082706863060595\n",
      "  batch 2999 loss: 0.3172607504837215\n",
      "  batch 3999 loss: 0.3074832267779857\n",
      "LOSS train 0.3074832267779857 valid 0.3269003629684448\n",
      "Epoch [62/100], Loss: 0.3269\n",
      "Epoch: 63\n",
      "  batch 999 loss: 0.333127419706434\n",
      "  batch 1999 loss: 0.3190432722773403\n",
      "  batch 2999 loss: 0.31565731260180474\n",
      "  batch 3999 loss: 0.3059485098514706\n",
      "LOSS train 0.3059485098514706 valid 0.3251395523548126\n",
      "Epoch [63/100], Loss: 0.3251\n",
      "Epoch: 64\n",
      "  batch 999 loss: 0.33155455281957985\n",
      "  batch 1999 loss: 0.31732928262092175\n",
      "  batch 2999 loss: 0.3141155457012355\n",
      "  batch 3999 loss: 0.304479563318193\n",
      "LOSS train 0.304479563318193 valid 0.32343700528144836\n",
      "Epoch [64/100], Loss: 0.3234\n",
      "Epoch: 65\n",
      "  batch 999 loss: 0.33004786690324545\n",
      "  batch 1999 loss: 0.3156803782787174\n",
      "  batch 2999 loss: 0.3126311695352197\n",
      "  batch 3999 loss: 0.3030714533664286\n",
      "LOSS train 0.3030714533664286 valid 0.3217909038066864\n",
      "Epoch [65/100], Loss: 0.3218\n",
      "Epoch: 66\n",
      "  batch 999 loss: 0.32860205591842534\n",
      "  batch 1999 loss: 0.31409268566221\n",
      "  batch 2999 loss: 0.3112009288519621\n",
      "  batch 3999 loss: 0.3017206179220229\n",
      "LOSS train 0.3017206179220229 valid 0.32020097970962524\n",
      "Epoch [66/100], Loss: 0.3202\n",
      "Epoch: 67\n",
      "  batch 999 loss: 0.32721274688094854\n",
      "  batch 1999 loss: 0.3125632360242307\n",
      "  batch 2999 loss: 0.3098226388376206\n",
      "  batch 3999 loss: 0.30042475543357433\n",
      "LOSS train 0.30042475543357433 valid 0.3186652362346649\n",
      "Epoch [67/100], Loss: 0.3187\n",
      "Epoch: 68\n",
      "  batch 999 loss: 0.32587581197544935\n",
      "  batch 1999 loss: 0.3110901327505708\n",
      "  batch 2999 loss: 0.30849435489438476\n",
      "  batch 3999 loss: 0.2991819291822612\n",
      "LOSS train 0.2991819291822612 valid 0.3171839714050293\n",
      "Epoch [68/100], Loss: 0.3172\n",
      "Epoch: 69\n",
      "  batch 999 loss: 0.32458768915385006\n",
      "  batch 1999 loss: 0.30967192589491604\n",
      "  batch 2999 loss: 0.30721430959552526\n",
      "  batch 3999 loss: 0.29799023239687084\n",
      "LOSS train 0.29799023239687084 valid 0.3157583475112915\n",
      "Epoch [69/100], Loss: 0.3158\n",
      "Epoch: 70\n",
      "  batch 999 loss: 0.3233444965444505\n",
      "  batch 1999 loss: 0.30830717261508106\n",
      "  batch 2999 loss: 0.3059804397709668\n",
      "  batch 3999 loss: 0.2968471647202969\n",
      "LOSS train 0.2968471647202969 valid 0.31438496708869934\n",
      "Epoch [70/100], Loss: 0.3144\n",
      "Epoch: 71\n",
      "  batch 999 loss: 0.32214261585846543\n",
      "  batch 1999 loss: 0.30699388426356017\n",
      "  batch 2999 loss: 0.3047899197153747\n",
      "  batch 3999 loss: 0.29574940300919117\n",
      "LOSS train 0.29574940300919117 valid 0.3130645751953125\n",
      "Epoch [71/100], Loss: 0.3131\n",
      "Epoch: 72\n",
      "  batch 999 loss: 0.32097815980017186\n",
      "  batch 1999 loss: 0.3057295290566981\n",
      "  batch 2999 loss: 0.30363954399712384\n",
      "  batch 3999 loss: 0.29469286612793805\n",
      "LOSS train 0.29469286612793805 valid 0.31179505586624146\n",
      "Epoch [72/100], Loss: 0.3118\n",
      "Epoch: 73\n",
      "  batch 999 loss: 0.31984731278568507\n",
      "  batch 1999 loss: 0.30451083039492366\n",
      "  batch 2999 loss: 0.3025255966335535\n",
      "  batch 3999 loss: 0.29367295136861504\n",
      "LOSS train 0.29367295136861504 valid 0.31057387590408325\n",
      "Epoch [73/100], Loss: 0.3106\n",
      "Epoch: 74\n",
      "  batch 999 loss: 0.31874630043655633\n",
      "  batch 1999 loss: 0.3033341880664229\n",
      "  batch 2999 loss: 0.30144424764066935\n",
      "  batch 3999 loss: 0.2926851611994207\n",
      "LOSS train 0.2926851611994207 valid 0.3094002306461334\n",
      "Epoch [74/100], Loss: 0.3094\n",
      "Epoch: 75\n",
      "  batch 999 loss: 0.31767164804413917\n",
      "  batch 1999 loss: 0.3021955558201298\n",
      "  batch 2999 loss: 0.3003919584751129\n",
      "  batch 3999 loss: 0.29172513292729857\n",
      "LOSS train 0.29172513292729857 valid 0.30827027559280396\n",
      "Epoch [75/100], Loss: 0.3083\n",
      "Epoch: 76\n",
      "  batch 999 loss: 0.3166202079765499\n",
      "  batch 1999 loss: 0.30109116843529043\n",
      "  batch 2999 loss: 0.2993653188440949\n",
      "  batch 3999 loss: 0.29078913166560233\n",
      "LOSS train 0.29078913166560233 valid 0.30718186497688293\n",
      "Epoch [76/100], Loss: 0.3072\n",
      "Epoch: 77\n",
      "  batch 999 loss: 0.31558925921469927\n",
      "  batch 1999 loss: 0.30001747027412057\n",
      "  batch 2999 loss: 0.2983613901361823\n",
      "  batch 3999 loss: 0.2898738687951118\n",
      "LOSS train 0.2898738687951118 valid 0.30613261461257935\n",
      "Epoch [77/100], Loss: 0.3061\n",
      "Epoch: 78\n",
      "  batch 999 loss: 0.314576378326863\n",
      "  batch 1999 loss: 0.29897119434084746\n",
      "  batch 2999 loss: 0.2973775754794478\n",
      "  batch 3999 loss: 0.28897673687525094\n",
      "LOSS train 0.28897673687525094 valid 0.3051203489303589\n",
      "Epoch [78/100], Loss: 0.3051\n",
      "Epoch: 79\n",
      "  batch 999 loss: 0.31357951151952146\n",
      "  batch 1999 loss: 0.2979496590523049\n",
      "  batch 2999 loss: 0.2964118048939854\n",
      "  batch 3999 loss: 0.2880957796722651\n",
      "LOSS train 0.2880957796722651 valid 0.3041418790817261\n",
      "Epoch [79/100], Loss: 0.3041\n",
      "Epoch: 80\n",
      "  batch 999 loss: 0.3125970990844071\n",
      "  batch 1999 loss: 0.296950538164936\n",
      "  batch 2999 loss: 0.2954622740317136\n",
      "  batch 3999 loss: 0.28722947954013944\n",
      "LOSS train 0.28722947954013944 valid 0.3031960129737854\n",
      "Epoch [80/100], Loss: 0.3032\n",
      "Epoch: 81\n",
      "  batch 999 loss: 0.3116277691796422\n",
      "  batch 1999 loss: 0.295972019857727\n",
      "  batch 2999 loss: 0.29452759873121975\n",
      "  batch 3999 loss: 0.2863767378591001\n",
      "LOSS train 0.2863767378591001 valid 0.30228060483932495\n",
      "Epoch [81/100], Loss: 0.3023\n",
      "Epoch: 82\n",
      "  batch 999 loss: 0.31067050801962615\n",
      "  batch 1999 loss: 0.29501250402349977\n",
      "  batch 2999 loss: 0.29360673857480285\n",
      "  batch 3999 loss: 0.28553687753900886\n",
      "LOSS train 0.28553687753900886 valid 0.30139487981796265\n",
      "Epoch [82/100], Loss: 0.3014\n",
      "Epoch: 83\n",
      "  batch 999 loss: 0.3097247097454965\n",
      "  batch 1999 loss: 0.29407103643286975\n",
      "  batch 2999 loss: 0.292698887784034\n",
      "  batch 3999 loss: 0.2847094875331968\n",
      "LOSS train 0.2847094875331968 valid 0.3005364239215851\n",
      "Epoch [83/100], Loss: 0.3005\n",
      "Epoch: 84\n",
      "  batch 999 loss: 0.3087897578850389\n",
      "  batch 1999 loss: 0.2931466161813587\n",
      "  batch 2999 loss: 0.29180354964733124\n",
      "  batch 3999 loss: 0.2838942498024553\n",
      "LOSS train 0.2838942498024553 valid 0.29970434308052063\n",
      "Epoch [84/100], Loss: 0.2997\n",
      "Epoch: 85\n",
      "  batch 999 loss: 0.30786544175818564\n",
      "  batch 1999 loss: 0.2922386235976592\n",
      "  batch 2999 loss: 0.2909203166514635\n",
      "  batch 3999 loss: 0.28309108440764247\n",
      "LOSS train 0.28309108440764247 valid 0.2988974452018738\n",
      "Epoch [85/100], Loss: 0.2989\n",
      "Epoch: 86\n",
      "  batch 999 loss: 0.3069518038332462\n",
      "  batch 1999 loss: 0.29134667627792804\n",
      "  batch 2999 loss: 0.2900491443686187\n",
      "  batch 3999 loss: 0.2823001218680292\n",
      "LOSS train 0.2823001218680292 valid 0.2981140911579132\n",
      "Epoch [86/100], Loss: 0.2981\n",
      "Epoch: 87\n",
      "  batch 999 loss: 0.30604897790402175\n",
      "  batch 1999 loss: 0.2904703871048987\n",
      "  batch 2999 loss: 0.289190198617056\n",
      "  batch 3999 loss: 0.28152157324925065\n",
      "LOSS train 0.28152157324925065 valid 0.297355055809021\n",
      "Epoch [87/100], Loss: 0.2974\n",
      "Epoch: 88\n",
      "  batch 999 loss: 0.30515735257789495\n",
      "  batch 1999 loss: 0.2896098200110719\n",
      "  batch 2999 loss: 0.2883437006454915\n",
      "  batch 3999 loss: 0.28075582945533095\n",
      "LOSS train 0.28075582945533095 valid 0.2966178357601166\n",
      "Epoch [88/100], Loss: 0.2966\n",
      "Epoch: 89\n",
      "  batch 999 loss: 0.3042775400709361\n",
      "  batch 1999 loss: 0.28876487552188335\n",
      "  batch 2999 loss: 0.2875100954286754\n",
      "  batch 3999 loss: 0.28000326863490044\n",
      "LOSS train 0.28000326863490044 valid 0.29590117931365967\n",
      "Epoch [89/100], Loss: 0.2959\n",
      "Epoch: 90\n",
      "  batch 999 loss: 0.3034101478345692\n",
      "  batch 1999 loss: 0.2879356797672808\n",
      "  batch 2999 loss: 0.2866898761000484\n",
      "  batch 3999 loss: 0.2792642740607262\n",
      "LOSS train 0.2792642740607262 valid 0.29520511627197266\n",
      "Epoch [90/100], Loss: 0.2952\n",
      "Epoch: 91\n",
      "  batch 999 loss: 0.30255593764968214\n",
      "  batch 1999 loss: 0.28712238547205926\n",
      "  batch 2999 loss: 0.28588342211954293\n",
      "  batch 3999 loss: 0.27853931982629\n",
      "LOSS train 0.27853931982629 valid 0.29452747106552124\n",
      "Epoch [91/100], Loss: 0.2945\n",
      "Epoch: 92\n",
      "  batch 999 loss: 0.3017156896777451\n",
      "  batch 1999 loss: 0.2863251547981054\n",
      "  batch 2999 loss: 0.2850914656892419\n",
      "  batch 3999 loss: 0.27782889940217137\n",
      "LOSS train 0.27782889940217137 valid 0.2938690483570099\n",
      "Epoch [92/100], Loss: 0.2939\n",
      "Epoch: 93\n",
      "  batch 999 loss: 0.30089027016982434\n",
      "  batch 1999 loss: 0.2855441468823701\n",
      "  batch 2999 loss: 0.2843144789263606\n",
      "  batch 3999 loss: 0.27713343728892503\n",
      "LOSS train 0.27713343728892503 valid 0.2932276427745819\n",
      "Epoch [93/100], Loss: 0.2932\n",
      "Epoch: 94\n",
      "  batch 999 loss: 0.3000803853720427\n",
      "  batch 1999 loss: 0.2847794215492904\n",
      "  batch 2999 loss: 0.28355264115612955\n",
      "  batch 3999 loss: 0.27645311181433496\n",
      "LOSS train 0.27645311181433496 valid 0.2926024794578552\n",
      "Epoch [94/100], Loss: 0.2926\n",
      "Epoch: 95\n",
      "  batch 999 loss: 0.29928660896606746\n",
      "  batch 1999 loss: 0.28403107944317163\n",
      "  batch 2999 loss: 0.282806495080702\n",
      "  batch 3999 loss: 0.27578814315982164\n",
      "LOSS train 0.27578814315982164 valid 0.2919920086860657\n",
      "Epoch [95/100], Loss: 0.2920\n",
      "Epoch: 96\n",
      "  batch 999 loss: 0.2985094229876995\n",
      "  batch 1999 loss: 0.28329888701625167\n",
      "  batch 2999 loss: 0.2820760433739051\n",
      "  batch 3999 loss: 0.2751386198066175\n",
      "LOSS train 0.2751386198066175 valid 0.29139626026153564\n",
      "Epoch [96/100], Loss: 0.2914\n",
      "Epoch: 97\n",
      "  batch 999 loss: 0.29774922128394243\n",
      "  batch 1999 loss: 0.28258284090459346\n",
      "  batch 2999 loss: 0.28136148108635095\n",
      "  batch 3999 loss: 0.2745045747794211\n",
      "LOSS train 0.2745045747794211 valid 0.2908145487308502\n",
      "Epoch [97/100], Loss: 0.2908\n",
      "Epoch: 98\n",
      "  batch 999 loss: 0.2970062145516276\n",
      "  batch 1999 loss: 0.2818827122375369\n",
      "  batch 2999 loss: 0.2806626893756911\n",
      "  batch 3999 loss: 0.27388576432317496\n",
      "LOSS train 0.27388576432317496 valid 0.29024454951286316\n",
      "Epoch [98/100], Loss: 0.2902\n",
      "Epoch: 99\n",
      "  batch 999 loss: 0.29628047394752505\n",
      "  batch 1999 loss: 0.28119809919781985\n",
      "  batch 2999 loss: 0.2799794466616586\n",
      "  batch 3999 loss: 0.27328193484991786\n",
      "LOSS train 0.27328193484991786 valid 0.28968676924705505\n",
      "Epoch [99/100], Loss: 0.2897\n",
      "Epoch: 100\n",
      "  batch 999 loss: 0.2955717546660453\n",
      "  batch 1999 loss: 0.2805286305584013\n",
      "  batch 2999 loss: 0.27931141351535915\n",
      "  batch 3999 loss: 0.2726926893088967\n",
      "LOSS train 0.2726926893088967 valid 0.2891395688056946\n",
      "Epoch [100/100], Loss: 0.2891\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Training loop\n",
    "model = MLPModel()\n",
    "\n",
    "# transforming data into tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test,   dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test,   dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset,       batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(dataloader, model, optimizer, mse)\n",
    "\n",
    "    running_vloss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(test_dataset):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = mse(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "    \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(f'LOSS train {avg_loss} valid {avg_vloss}')\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_vloss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and Training the Model with Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;tanh&#x27;, max_iter=500, warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor(activation=&#x27;tanh&#x27;, max_iter=500, warm_start=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='tanh', max_iter=500, warm_start=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(100,),\n",
    "    activation='tanh',\n",
    "    max_iter=500,\n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/xavier/miniconda3/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.87315703 0.48160248 0.42741962 0.8547205  0.90548295]\n",
      "Mean MSE: 0.7084765142383539\n",
      "Std. dev. of MSE: 0.20870233221369536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X_test, y_test, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Cross-validation scores:\", -scores)  # Negate scores to get MSE\n",
    "# Print the mean and standard deviation of the scores\n",
    "print(\"Mean MSE:\", -scores.mean())\n",
    "print(\"Std. dev. of MSE:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    " \n",
    "# Save the model weights\n",
    "#dump(model, \"mlp_regressor_weights_2.joblib\")\n",
    "#print(\"Model weights saved\")\n",
    "\n",
    "# load the model later\n",
    "# loaded_model = load(\"mlp_regressor_weights.joblib\")\n",
    "# print(\"Model weights loaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
